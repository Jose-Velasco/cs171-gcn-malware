{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from os import walk\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce GTX 1080\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Callable\n",
    "\n",
    "\n",
    "# class APICallGraphDataset(Dataset):\n",
    "#     def __init__(self, root: str, apiCallEmbeddingsFilePath: str, weighted: bool, allClassLabels: dict[str, int], transform=None, pre_transform=None, pre_filter=None):\n",
    "#         # super().__init__(root, transform, pre_transform, pre_filter)\n",
    "#         # self.areAttributesInitialized = False\n",
    "#         # self.apiCallEmbeddingsFilePath: str = apiCallEmbeddingsFilePath\n",
    "#         # self.apiToNodeIndex: dict[str, int] = {}\n",
    "#         # self.weighted = weighted\n",
    "#         # self.nodeFeatures: torch.Tensor | None = None\n",
    "#         # self.allClassLabels: dict[str, int] = allClassLabels\n",
    "#         self.areAttributesInitialized = False\n",
    "#         self.apiCallEmbeddingsFilePath: str = apiCallEmbeddingsFilePath\n",
    "#         self.apiToNodeIndex: dict[str, int] = {}\n",
    "#         self.weighted = weighted\n",
    "#         self.nodeFeatures: torch.Tensor | None = None\n",
    "#         self.allClassLabels: dict[str, int] = allClassLabels\n",
    "#         super().__init__(root, transform, pre_transform, pre_filter)\n",
    "   \n",
    "#     @property\n",
    "#     def raw_file_names(self):\n",
    "#         # rootDir: str = super().root\n",
    "#         rootDir: str = self.root\n",
    "#         filePaths: list[str] = []\n",
    "#         for subdir, dirs, files in walk(osp.join(rootDir, \"raw\")):\n",
    "#             for file in files:\n",
    "#                 filePath: str = osp.join(subdir, file)\n",
    "#                 filePaths.append(filePath)\n",
    "#                 # filePaths.append(file)\n",
    "#         return filePaths\n",
    "\n",
    "#     @property\n",
    "#     def processed_file_names(self):\n",
    "#         rawFilePaths: list[str] = self.raw_file_names\n",
    "#         processedFileNames: list[str] = []\n",
    "#         for idx, filePath in enumerate(rawFilePaths):\n",
    "#             filePathObj = Path(filePath)\n",
    "#             # fileName = filePathObj.stem\n",
    "#             # parentDirPath = filePathObj.parent\n",
    "#             # parentDirName = parentDirPath.stem\n",
    "#             # procFileName = f\"{parentDirName}_{fileName}_{idx}.pt\"\n",
    "#             procFileName = self._make_file_name(filePathObj, idx)\n",
    "#             processedFileNames.append(procFileName)\n",
    "#         return processedFileNames\n",
    "    \n",
    "#     # @property\n",
    "#     # def processed_paths(self) -> list[str]:\n",
    "#     #     r\"\"\"The absolute filepaths that must be present in order to skip\n",
    "#     #     processing.\n",
    "#     #     \"\"\"\n",
    "#     #     files = self.processed_file_names\n",
    "#     #     # Prevent a common source of error in which `file_names` are not\n",
    "#     #     # defined as a property.\n",
    "#     #     if isinstance(files, Callable):\n",
    "#     #         files = files()\n",
    "#     #     return [osp.join(self.processed_dir, f) for f in self.to_list(files)]\n",
    "\n",
    "#     def download(self):\n",
    "#         # Download to `self.raw_dir`.\n",
    "#         pass\n",
    "\n",
    "#     def process(self):\n",
    "#         try:\n",
    "#             self.areAttributesInitialized\n",
    "#         except AttributeError as e:\n",
    "#             print(e)\n",
    "#             return\n",
    "#         self.nodeFeatures = self._get_node_feature()\n",
    "#         for idx, raw_path in enumerate(self.raw_file_names):\n",
    "#             filePathObj: Path = Path(raw_path)\n",
    "#             outputGraphFileName = self._make_file_name(filePathObj, idx)\n",
    "#             # processedFilePath = f\"{outputGraphFileName}\"\n",
    "#             edgesWeightsDict: dict[tuple[str, str], int] = self._get_edge_weight_features(raw_path)\n",
    "#             graphLabel = self._get_label(filePathObj)\n",
    "#             oneHotEncGraphLabel = self.one_hot_encode(graphLabel)\n",
    "\n",
    "#             allEdgeFeatures: list[int] = []\n",
    "#             allEdges: list[list] = [[],[]]\n",
    "#             for edgeTuple, weight in edgesWeightsDict.items():\n",
    "#                 # undirected graph thus, need to have the same wight per direction\n",
    "#                 # and have source -> destination and destination -> source\n",
    "#                 allEdgeFeatures += [weight, weight]\n",
    "#                 allEdges[0] += [self.apiToNodeIndex[edgeTuple[0]], self.apiToNodeIndex[edgeTuple[1]]]\n",
    "#                 allEdges[1] += [self.apiToNodeIndex[edgeTuple[1]], self.apiToNodeIndex[edgeTuple[0]]]\n",
    "            \n",
    "#             edgeIndices = torch.tensor(allEdges)\n",
    "#             edgeFeatures = torch.tensor(allEdgeFeatures, dtype=torch.int64)\n",
    "#             # Read data from `raw_path`.\n",
    "#             data = Data(\n",
    "#                 x = self.nodeFeatures,\n",
    "#                 edge_index = edgeIndices,\n",
    "#                 edge_attr = edgeFeatures,\n",
    "#                 y=oneHotEncGraphLabel\n",
    "#             )\n",
    "\n",
    "#             # filters out data\n",
    "#             if self.pre_filter is not None and not self.pre_filter(data):\n",
    "#                 continue\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data = self.pre_transform(data)\n",
    "\n",
    "#             torch.save(data, osp.join(self.processed_dir, outputGraphFileName))\n",
    "\n",
    "#     def len(self):\n",
    "#         return len(self.processed_file_names)\n",
    "\n",
    "#     def get(self, idx):\n",
    "#         pattern = f\"{self.processed_dir}/*_{idx}.pt\"\n",
    "#         matchingFiles = glob.glob(pattern)\n",
    "#         if matchingFiles:\n",
    "#             return torch.load(osp.join(matchingFiles[0]))\n",
    "#         raise FileNotFoundError(f\"The specified file data object not found: {idx = }\")\n",
    "    \n",
    "#     def _get_node_feature(self) -> torch.Tensor:\n",
    "#         \"\"\" \n",
    "#         This will return a tensor / 2d array of the shape\n",
    "#         [Number of Nodes, Node Feature size]\n",
    "#         \"\"\"\n",
    "#         apiCallWordVector = KeyedVectors.load(self.apiCallEmbeddingsFilePath)\n",
    "#         allNodeFeats = []\n",
    "#         nodeIndex = 0\n",
    "#         for apiCall, t in apiCallWordVector.key_to_index.items():\n",
    "#             allNodeFeats.append(apiCallWordVector[apiCall])\n",
    "#             self.apiToNodeIndex[apiCall] = nodeIndex\n",
    "#             nodeIndex += 1\n",
    "#         allNodeFeats = np.asarray(allNodeFeats)\n",
    "#         return torch.tensor(allNodeFeats, dtype=torch.float32)\n",
    "    \n",
    "#     def _get_edge_weight_features(self, rawFilePath: str) -> dict[tuple[str, str], int]:\n",
    "#         # [Number of edge, Edge Feature size]\n",
    "#         if not self.weighted:\n",
    "#             return []\n",
    "#         edgeWeight: dict[tuple[str, str], int] = {}\n",
    "\n",
    "#         # for rawFilePath in self.raw_paths:\n",
    "#         with open(rawFilePath, \"r\") as apiLog:\n",
    "#             for line1, line2 in zip(apiLog, apiLog):\n",
    "#                 if line1 is None or line2 is None:\n",
    "#                     continue\n",
    "#                 line1Norm = line1.lower().strip(\"\\n\")\n",
    "#                 line2Norm = line1.lower().strip(\"\\n\")\n",
    "                \n",
    "#                 if (line1Norm, line2Norm) not in edgeWeight:\n",
    "#                     edgeWeight[(line1Norm, line2Norm)] = 1\n",
    "#                 else:\n",
    "#                     edgeWeight[(line1Norm, line2Norm)] += 1\n",
    "#         return edgeWeight\n",
    "    \n",
    "#     def _get_label(self, rawFilePath: Path):\n",
    "#         # parent dir names are the family the malware belongs to\n",
    "#         # thus is the graph label\n",
    "#         parentDirPath = rawFilePath.parent\n",
    "#         parentDirName = parentDirPath.stem\n",
    "#         return parentDirName\n",
    "    \n",
    "#     def _make_file_name(self, rawFilePath: Path, index: int) -> str:\n",
    "#         fileName = rawFilePath.stem\n",
    "#         parentDirPath = rawFilePath.parent\n",
    "#         parentDirName = parentDirPath.stem\n",
    "#         processedFileName = f\"{parentDirName}_{fileName}_{index}.pt\"\n",
    "#         return processedFileName\n",
    "    \n",
    "#     def one_hot_encode(self, familyLabel: str):\n",
    "#         numericalFamilyValue = self.allClassLabels[familyLabel]\n",
    "#         numClasses = len(self.allClassLabels)\n",
    "#         oneHotEncodedLabel = torch.nn.functional.one_hot(torch.tensor(numericalFamilyValue), numClasses)\n",
    "#         return oneHotEncodedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adload', 'bancos', 'onlinegames', 'vbinject', 'vundo', 'winwebsec', 'zwangi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directories that samples are in are the families they belong to aka Labels\n",
    "rawDataPath = Path(\"./AllFiles_CleanLogAPI/raw\")\n",
    "familyLabels = [dirEntryLabel.stem.lower().strip().strip(\"\\n\") for dirEntryLabel in rawDataPath.iterdir() if dirEntryLabel.is_dir()]\n",
    "familyLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {label: index for index, label in enumerate(familyLabels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = APICallGraphDataset(\n",
    "    root=\"./AllFiles_CleanLogAPI\",\n",
    "    apiCallEmbeddingsFilePath=\"./APICallword2vec_VecSize100_skipGram.wordvectors\",\n",
    "    weighted=True,\n",
    "    allClassLabels=label_to_index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing XDXDX!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# if dataset.has_process:\n",
    "# dataset._process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  7,  7, 16, 16, 10, 10, 11, 11,  5,  5,  6,  6,  1,  1, 44, 44,\n",
      "          3,  3, 33, 33, 23, 23, 37, 37, 40, 40, 24, 24,  4,  4, 29, 29, 12, 12,\n",
      "         34, 34],\n",
      "        [ 0,  0,  7,  7, 16, 16, 10, 10, 11, 11,  5,  5,  6,  6,  1,  1, 44, 44,\n",
      "          3,  3, 33, 33, 23, 23, 37, 37, 40, 40, 24, 24,  4,  4, 29, 29, 12, 12,\n",
      "         34, 34]])\n",
      "tensor([[-1.9541e-01,  1.0137e-01,  2.3452e-01,  ...,  2.1669e-01,\n",
      "         -2.0797e-01, -1.3969e-01],\n",
      "        [-2.6427e-04,  9.9156e-02,  3.5102e-01,  ..., -1.7724e-01,\n",
      "         -1.5234e-01, -1.6609e-01],\n",
      "        [-1.3142e-01,  2.4001e-01, -3.4651e-01,  ..., -1.0048e+00,\n",
      "         -5.2757e-01,  3.3050e-01],\n",
      "        ...,\n",
      "        [ 8.3066e-02, -1.3083e-01,  7.4207e-02,  ..., -1.4956e-01,\n",
      "         -6.4795e-02,  1.6348e-02],\n",
      "        [ 1.3425e-01, -7.5131e-02,  5.1778e-02,  ..., -1.7396e-01,\n",
      "         -7.8794e-02,  1.5917e-02],\n",
      "        [ 7.1565e-02, -1.2998e-01,  4.9647e-02,  ..., -1.5486e-01,\n",
      "         -2.1107e-02, -1.0939e-02]])\n",
      "tensor([21, 21,  4,  4,  1,  1,  2,  2,  4,  4,  5,  5,  6,  6,  5,  5,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,\n",
      "         1,  1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0].edge_index)\n",
    "print(dataset[0].x)\n",
    "print(dataset[0].edge_attr)\n",
    "print(dataset[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 7,  7],\n",
      "        [ 7,  7],\n",
      "        [16, 16],\n",
      "        [16, 16],\n",
      "        [10, 10],\n",
      "        [10, 10],\n",
      "        [11, 11],\n",
      "        [11, 11],\n",
      "        [ 5,  5],\n",
      "        [ 5,  5],\n",
      "        [ 6,  6],\n",
      "        [ 6,  6],\n",
      "        [27, 27],\n",
      "        [27, 27],\n",
      "        [36, 36],\n",
      "        [36, 36],\n",
      "        [32, 32],\n",
      "        [32, 32],\n",
      "        [ 9,  9],\n",
      "        [ 9,  9],\n",
      "        [40, 40],\n",
      "        [40, 40],\n",
      "        [ 1,  1],\n",
      "        [ 1,  1],\n",
      "        [29, 29],\n",
      "        [29, 29],\n",
      "        [22, 22],\n",
      "        [22, 22],\n",
      "        [12, 12],\n",
      "        [12, 12],\n",
      "        [ 3,  3],\n",
      "        [ 3,  3],\n",
      "        [28, 28],\n",
      "        [28, 28],\n",
      "        [14, 14],\n",
      "        [14, 14],\n",
      "        [38, 38],\n",
      "        [38, 38],\n",
      "        [15, 15],\n",
      "        [15, 15]])\n",
      "tensor([[-1.9541e-01,  1.0137e-01,  2.3452e-01,  ...,  2.1669e-01,\n",
      "         -2.0797e-01, -1.3969e-01],\n",
      "        [-2.6427e-04,  9.9156e-02,  3.5102e-01,  ..., -1.7724e-01,\n",
      "         -1.5234e-01, -1.6609e-01],\n",
      "        [-1.3142e-01,  2.4001e-01, -3.4651e-01,  ..., -1.0048e+00,\n",
      "         -5.2757e-01,  3.3050e-01],\n",
      "        ...,\n",
      "        [ 8.3066e-02, -1.3083e-01,  7.4207e-02,  ..., -1.4956e-01,\n",
      "         -6.4795e-02,  1.6348e-02],\n",
      "        [ 1.3425e-01, -7.5131e-02,  5.1778e-02,  ..., -1.7396e-01,\n",
      "         -7.8794e-02,  1.5917e-02],\n",
      "        [ 7.1565e-02, -1.2998e-01,  4.9647e-02,  ..., -1.5486e-01,\n",
      "         -2.1107e-02, -1.0939e-02]])\n",
      "tensor([16, 16,  4,  4,  1,  1,  4,  4,  6,  6,  5,  5,  7,  7,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  3,  3,  2,  2,  2,  2,  1,  1,  2,  2,  1,  1,\n",
      "         5,  5,  1,  1,  1,  1])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1].edge_index.t())\n",
    "print(dataset[1].x)\n",
    "print(dataset[1].edge_attr)\n",
    "print(dataset[1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 7,  7],\n",
      "        [ 7,  7],\n",
      "        [16, 16],\n",
      "        [16, 16],\n",
      "        [ 1,  1],\n",
      "        [ 1,  1],\n",
      "        [ 5,  5],\n",
      "        [ 5,  5],\n",
      "        [15, 15],\n",
      "        [15, 15],\n",
      "        [ 6,  6],\n",
      "        [ 6,  6],\n",
      "        [11, 11],\n",
      "        [11, 11],\n",
      "        [10, 10],\n",
      "        [10, 10],\n",
      "        [20, 20],\n",
      "        [20, 20],\n",
      "        [ 4,  4],\n",
      "        [ 4,  4],\n",
      "        [23, 23],\n",
      "        [23, 23],\n",
      "        [24, 24],\n",
      "        [24, 24],\n",
      "        [13, 13],\n",
      "        [13, 13],\n",
      "        [ 3,  3],\n",
      "        [ 3,  3],\n",
      "        [ 9,  9],\n",
      "        [ 9,  9],\n",
      "        [ 2,  2],\n",
      "        [ 2,  2],\n",
      "        [ 8,  8],\n",
      "        [ 8,  8],\n",
      "        [18, 18],\n",
      "        [18, 18],\n",
      "        [49, 49],\n",
      "        [49, 49],\n",
      "        [46, 46],\n",
      "        [46, 46]])\n",
      "tensor([[-1.9541e-01,  1.0137e-01,  2.3452e-01,  ...,  2.1669e-01,\n",
      "         -2.0797e-01, -1.3969e-01],\n",
      "        [-2.6427e-04,  9.9156e-02,  3.5102e-01,  ..., -1.7724e-01,\n",
      "         -1.5234e-01, -1.6609e-01],\n",
      "        [-1.3142e-01,  2.4001e-01, -3.4651e-01,  ..., -1.0048e+00,\n",
      "         -5.2757e-01,  3.3050e-01],\n",
      "        ...,\n",
      "        [ 8.3066e-02, -1.3083e-01,  7.4207e-02,  ..., -1.4956e-01,\n",
      "         -6.4795e-02,  1.6348e-02],\n",
      "        [ 1.3425e-01, -7.5131e-02,  5.1778e-02,  ..., -1.7396e-01,\n",
      "         -7.8794e-02,  1.5917e-02],\n",
      "        [ 7.1565e-02, -1.2998e-01,  4.9647e-02,  ..., -1.5486e-01,\n",
      "         -2.1107e-02, -1.0939e-02]])\n",
      "tensor([ 31,  31,   6,   6,   2,   2,  18,  18,   7,   7,   8,   8,   4,   4,\n",
      "          4,   4,   5,   5,   2,   2,  34,  34,   2,   2,   2,   2,   2,   2,\n",
      "        124, 124,  52,  52, 150, 150,   2,   2,   2,   2,   1,   1,   1,   1])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[400].edge_index.t())\n",
    "print(dataset[400].x)\n",
    "print(dataset[400].edge_attr)\n",
    "print(dataset[400].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\n",
    "#     [ 0,  0,  7,  7, 16, 16, 10, 10, 11, 11,  5,  5,  6,  6,  1,  1, 44, 44, 3,  3, 33, 33, 23, 23, 37, 37, 40, 40, 24, 24,  4,  4, 29, 29, 12, 12, 34, 34],\n",
    "#     [ 0,  0,  7,  7, 16, 16, 10, 10, 11, 11,  5,  5,  6,  6,  1,  1, 44, 44, 3,  3, 33, 33, 23, 23, 37, 37, 40, 40, 24, 24,  4,  4, 29, 29, 12, 12, 34, 34]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APICallGraphDataset (#graphs=492):\n",
      "+------------+----------+----------+\n",
      "|            |   #nodes |   #edges |\n",
      "|------------+----------+----------|\n",
      "| mean       |       79 |     33.8 |\n",
      "| std        |        0 |     11.2 |\n",
      "| min        |       79 |     10   |\n",
      "| quantile25 |       79 |     26   |\n",
      "| median     |       79 |     32   |\n",
      "| quantile75 |       79 |     42   |\n",
      "| max        |       79 |     70   |\n",
      "+------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "dataset.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: APICallGraphDataset(492):\n",
      "====================\n",
      "Number of graphs: 492\n",
      "Number of features: 100\n",
      "Number of classes: 2\n",
      "\n",
      "Data(x=[79, 100], edge_index=[2, 38], edge_attr=[38], y=[7])\n",
      "=============================================================\n",
      "Number of nodes: 79\n",
      "Number of edges: 38\n",
      "Average node degree: 0.48\n",
      "Has isolated nodes: True\n",
      "Has self-loops: True\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of features per Node: {dataset.num_node_features}')\n",
    "print(f'Number of edge features: {dataset.num_edge_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
