# %%
from torch.utils.data import Subset
from datasets import APICallGraphDataset
from pathlib import Path
from utils import generateFamilyLabels, generateLabelToIndex, balanceDataSplits
import numpy as np
from pathlib import Path
from torch_geometric.loader import DataLoader

# %%
rawDataPath = Path("./AllFiles_CleanLogAPI/raw")
familyLabels = generateFamilyLabels(rawDataPath)
labelsToIndices = generateLabelToIndex(familyLabels)
print(labelsToIndices)
# %%
# dataset = APICallGraphDataset(
#     root="./AllFiles_CleanLogAPI",
#     apiCallEmbeddingsFilePath="./APICallword2vec_VecSize100_skipGram.wordvectors",
#     weighted=True,
#     allClassLabels=labelsToIndices
# )


dataset = APICallGraphDataset(
    root="./AllFiles_CleanLogAPI",
    processSubDir="UndirectedWeighedGraphs",
    # undirected weighted
    fileNameMetaInfoSuffix="UD_W",
    apiCallEmbeddingsFilePath="./APICallword2vec_VecSize100_skipGram.wordvectors",
    weighted=True,
    allClassLabels=labelsToIndices,
)
# %%
SAVE_TRAIN_FNAME = "./dataSplits/undirectedWeightedTrainIndicesSplits.npy"
SAVE_VALIDATION_FNAME = "./dataSplits/undirectedWeightedValidationIndicesSplits.npy"
SAVE_TEST_FNAME = "./dataSplits/undirectedWeightedTestIndicesSplits.npy"

TRAIN_PERCENT = 0.8
VALIDATION_PERCENT = 0.1

# %%
if (not (Path(SAVE_TRAIN_FNAME).exists()) and not (Path(SAVE_VALIDATION_FNAME).exists()) and not (Path(SAVE_TEST_FNAME).exists())):
    print(f"Perform split: ({TRAIN_PERCENT}, {VALIDATION_PERCENT}, {1-VALIDATION_PERCENT-TRAIN_PERCENT})\n")
    train_indices, val_indices, test_indices = balanceDataSplits(labelsToIndices, dataset, TRAIN_PERCENT, VALIDATION_PERCENT)

    # Use Subset to create subsets of the dataset
    train_dataset = Subset(dataset, train_indices)
    val_dataset = Subset(dataset, val_indices)
    test_dataset = Subset(dataset, test_indices)

    np.save(SAVE_TRAIN_FNAME, train_indices)
    np.save(SAVE_VALIDATION_FNAME, val_indices)
    np.save(SAVE_TEST_FNAME, test_indices)
    print("!! Saving dataset split indices complete !!")

# %%
train_indices = np.load(SAVE_TRAIN_FNAME)
val_indices = np.load(SAVE_VALIDATION_FNAME)
test_indices = np.load(SAVE_TEST_FNAME)

train_dataset = Subset(dataset, train_indices)
val_dataset = Subset(dataset, val_indices)
test_dataset = Subset(dataset, test_indices)


# %%
def countClasses(dataLoader: DataLoader, num_classes: int):
    classCounts = [0] * num_classes
    for data in dataLoader:
        label = data.y
        classCounts[label] += 1
    return classCounts

# %%
NUM_CLASSES = 7

trainLoader = DataLoader(train_dataset)
valLoader = DataLoader(val_dataset)
testLoader = DataLoader(test_dataset)

trainNumClasses = countClasses(trainLoader, NUM_CLASSES)
valNumClasses = countClasses(valLoader, NUM_CLASSES)
testNumClasses = countClasses(testLoader, NUM_CLASSES)

# %%

print(trainNumClasses)
print(valNumClasses)
print(testNumClasses)

# %%
