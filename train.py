# %%
import torch
from torch.utils.data import Subset
from datasets import APICallGraphDataset
from pathlib import Path
from models import GCN
from torch_geometric.loader import DataLoader
from utils import (
    generateFamilyLabels, generateLabelToIndex, EarlyStopper,
    train, validationPhase, testPhase, generateAllPlots,
    plotTrainVSValidationLoss
)
from torchmetrics import MetricCollection
from torchmetrics.classification import (
    MulticlassAccuracy, MulticlassAUROC, MulticlassConfusionMatrix,
    MulticlassF1Score, MulticlassPrecision, MulticlassRecall, MulticlassROC,
    MulticlassPrecisionRecallCurve
    )
import numpy as np
from datetime import datetime
from dateutil import tz

# %%
rawDataPath = Path("./AllFiles_CleanLogAPI/raw")
familyLabels = generateFamilyLabels(rawDataPath)
labelsToIndices = generateLabelToIndex(familyLabels)

# %%
dataset = APICallGraphDataset(
    root="./AllFiles_CleanLogAPI",
    processSubDir="UndirectedWeighedGraphs",
    # undirected weighted
    fileNameMetaInfoSuffix="UD_W",
    apiCallEmbeddingsFilePath="./APICallword2vec_VecSize100_skipGram.wordvectors",
    weighted=True,
    allClassLabels=labelsToIndices
)

# %%
# DATA_SET_NUM_FEATURES = dataset.num_features
# DATA_SET_CLASSES = dataset.num_classes
DATA_SET_NUM_FEATURES = 100
DATA_SET_CLASSES = 7
NUM_EPOCHS = 5
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# make director manually
OUTPUT_DIR = "./experiments"
torch.manual_seed(12345)


# %%
# yTorch Geometric provides some useful utilities for working with graph datasets, e.g., we can shuffle the dataset and use the first
TRAIN_INDICES_FNAME = "./dataSplits/undirectedWeightedTrainIndicesSplits.npy"
VALIDATION_INDICES_FNAME = "./dataSplits/undirectedWeightedValidationIndicesSplits.npy"
TEST_INDICES_FNAME = "./dataSplits/undirectedWeightedTestIndicesSplits.npy"

train_indices = np.load(TRAIN_INDICES_FNAME)
val_indices = np.load(VALIDATION_INDICES_FNAME)
test_indices = np.load(TEST_INDICES_FNAME)

# %%
# Use Subset to create subsets of the dataset
train_dataset = Subset(dataset, train_indices)
val_dataset = Subset(dataset, val_indices)
test_dataset = Subset(dataset, test_indices)

# %%
LEN_TRAIN_DATASET = len(train_dataset)
LEN_VAL_DATASET = len(val_dataset) 
LEN_TEST_DATASET = len(test_dataset)

print(f'Number of training graphs: {LEN_TRAIN_DATASET}')
print(f'Number of validation graphs: {LEN_VAL_DATASET}')
print(f'Number of test graphs: {LEN_TEST_DATASET}')
print(f'Total graphs across all 3 datasets: {LEN_TEST_DATASET + LEN_VAL_DATASET + LEN_TRAIN_DATASET}')

# %%
# Mini-batching of graphs
# The length of this dimension is then equal to the number of examples grouped in a
# mini-batch and is typically referred to as the batch_size
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=12)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

for step, data in enumerate(train_loader):
    print(f'Step {step + 1}:')
    print('=======')
    print(f'Number of graphs in the current batch: {data.num_graphs}')
    print(data)
    print()

# Here, we opt for a batch_size of 16, leading to some (randomly shuffled) mini-batches, containing all  graphs.
# Furthermore, each Batch object is equipped with a batch vector, which maps each node to its respective graph in the batch:
# batch=[0,…,0,1,…,1,2,…]

# %%[markdown]
# Training a GNN for graph classification usually follows a simple recipe:
# 1. Embed each node by performing multiple rounds of message passing
# 2. Aggregate node embeddings into a unified graph embedding (readout layer)
# 3. Train a final classifier on the graph embedding


# %%[markdown]
# # GCN Weighted Undirected


# %%
# weighs undirected
model_W_UD = GCN(DATA_SET_NUM_FEATURES, DATA_SET_CLASSES, 64, weighted=True).to(DEVICE)
optimizer_W_UD = torch.optim.Adam(model_W_UD.parameters(), lr=0.001)
criterion_W_UD = torch.nn.CrossEntropyLoss()
print(model_W_UD)

# %%
metricCollection_W_UD = MetricCollection([
    MulticlassAccuracy(num_classes=DATA_SET_CLASSES, average="macro"),
    MulticlassROC(num_classes=DATA_SET_CLASSES, thresholds=None),
    MulticlassPrecisionRecallCurve(num_classes=DATA_SET_CLASSES, thresholds=None),
    MulticlassAUROC(num_classes=DATA_SET_CLASSES, average=None, thresholds=None),
    MulticlassConfusionMatrix(num_classes=DATA_SET_CLASSES),
    MulticlassF1Score(num_classes=DATA_SET_CLASSES),
    MulticlassPrecision(num_classes=DATA_SET_CLASSES),
    MulticlassRecall(num_classes=DATA_SET_CLASSES)
])
metricCollection_W_UD.to(DEVICE)
# %%
averageValLosses_W_UD: list[float] = []
averageTrainLoesses_W_UD: list[float] = []
earlyStopper = EarlyStopper(patience=3, min_delta=10)
for epoch in range(0, NUM_EPOCHS):
    average_train_loss, accuracy_train = train(model_W_UD, criterion_W_UD, optimizer_W_UD, train_loader, DEVICE)
    average_val_loss, accuracy_val = validationPhase(model_W_UD, criterion_W_UD, val_loader, metricCollection_W_UD, DEVICE)
    averageTrainLoesses_W_UD.append(average_train_loss)
    averageValLosses_W_UD.append(average_val_loss)
    trainAverageAccStr = f"average over each label Acc: {accuracy_train:.4f}"
    trainLossStr = f"Train Loss: {average_train_loss:.4f}"
    valLossStr = f'Validation Loss: {average_val_loss:.4f}'
    valAccuracyStr = f'Validation Accuracy: {accuracy_val:.4f}'
    print(f"Epoch: {(epoch+1):03d}/{NUM_EPOCHS}: {trainAverageAccStr}, {trainLossStr}, {valLossStr}, {valAccuracyStr}")
    # while loop it?
    if earlyStopper.early_stop(average_val_loss):
        break
    
# %%[markdown]
#  ## Results

#  #### Model Test
# %%
test_loss, test_accuracy = testPhase(model_W_UD, criterion_W_UD, test_loader, DEVICE)
print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {100 * test_accuracy:.2f}%')

# %%[markdown]

# ## Visualize the results

# %%
pst = tz.gettz('America/Los_Angeles')

now_datetime = datetime.now(pst)
# D=date, T=time
date_time_str = now_datetime.strftime("D%m-%dT%H_%M_%S")

# GCN Weight, Directed
EXPERIMENT_DIRECTORY_NAME_GCN_W_UD = f"{OUTPUT_DIR}/GCNWeighedUndirected{date_time_str}"

Path(EXPERIMENT_DIRECTORY_NAME_GCN_W_UD).mkdir(exist_ok=False)
# %%
# loss graph
plotTrainVSValidationLoss(averageTrainLoesses_W_UD, averageValLosses_W_UD, EXPERIMENT_DIRECTORY_NAME_GCN_W_UD)
# %%
# Extract all metrics from all steps
generateAllPlots(metricCollection_W_UD.values(), EXPERIMENT_DIRECTORY_NAME_GCN_W_UD)

# %%





# %%[markdown]
# # GCN Unweighted Undirected



# %%
# Unweighed undirected
model_UW_UD = GCN(DATA_SET_NUM_FEATURES, DATA_SET_CLASSES, 64, weighted=False).to(DEVICE)
optimizer_UW_UD = torch.optim.Adam(model_UW_UD.parameters(), lr=0.001)
criterion_UW_UD = torch.nn.CrossEntropyLoss()
print(model_UW_UD)

# %%
metricCollection_UW_UD = MetricCollection([
    MulticlassAccuracy(num_classes=DATA_SET_CLASSES, average="macro"),
    MulticlassROC(num_classes=DATA_SET_CLASSES, thresholds=None),
    MulticlassPrecisionRecallCurve(num_classes=DATA_SET_CLASSES, thresholds=None),
    MulticlassAUROC(num_classes=DATA_SET_CLASSES, average=None, thresholds=None),
    MulticlassConfusionMatrix(num_classes=DATA_SET_CLASSES),
    MulticlassF1Score(num_classes=DATA_SET_CLASSES),
    MulticlassPrecision(num_classes=DATA_SET_CLASSES),
    MulticlassRecall(num_classes=DATA_SET_CLASSES)
])
metricCollection_UW_UD.to(DEVICE)
# %%
averageValLosses_UW_UD: list[float] = []
averageTrainLoesses_UW_UD: list[float] = []
earlyStopper = EarlyStopper(patience=3, min_delta=10)
for epoch in range(0, NUM_EPOCHS):
    average_train_loss, accuracy_train = train(model_UW_UD, criterion_UW_UD, optimizer_UW_UD, train_loader, DEVICE)
    average_val_loss, accuracy_val = validationPhase(model_UW_UD, criterion_UW_UD, val_loader, metricCollection_UW_UD, DEVICE)
    averageTrainLoesses_UW_UD.append(average_train_loss)
    averageValLosses_UW_UD.append(average_val_loss)
    trainAverageAccStr = f"average over each label Acc: {accuracy_train:.4f}"
    trainLossStr = f"Train Loss: {average_train_loss:.4f}"
    valLossStr = f'Validation Loss: {average_val_loss:.4f}'
    valAccuracyStr = f'Validation Accuracy: {accuracy_val:.4f}'
    print(f"Epoch: {(epoch+1):03d}/{NUM_EPOCHS}: {trainAverageAccStr}, {trainLossStr}, {valLossStr}, {valAccuracyStr}")
    # while loop it?
    if earlyStopper.early_stop(average_val_loss):
        break
    
# %%[markdown]
#  ## Results

#  #### Model Test
# %%
test_loss_UW_UD, test_accuracy_UW_UD = testPhase(model_UW_UD, criterion_UW_UD, test_loader, DEVICE)
print(f'Test Loss: {test_loss_UW_UD:.4f}, Test Accuracy: {100 * test_accuracy_UW_UD:.2f}%')

# %%[markdown]

# ## Visualize the results

# %%
pst = tz.gettz('America/Los_Angeles')

now_datetime = datetime.now(pst)
# D=date, T=time
date_time_str = now_datetime.strftime("D%m-%dT%H_%M_%S")

# GCN Weight, Directed
EXPERIMENT_DIRECTORY_NAME_GCN_UW_UD = f"{OUTPUT_DIR}/GCNUnweighedUndirected{date_time_str}"

Path(EXPERIMENT_DIRECTORY_NAME_GCN_UW_UD).mkdir(exist_ok=False)
# %%
# loss graph
plotTrainVSValidationLoss(averageTrainLoesses_UW_UD, averageValLosses_UW_UD, EXPERIMENT_DIRECTORY_NAME_GCN_UW_UD)
# %%
# Extract all metrics from all steps
generateAllPlots(metricCollection_UW_UD.values(), EXPERIMENT_DIRECTORY_NAME_GCN_UW_UD)

# %%
